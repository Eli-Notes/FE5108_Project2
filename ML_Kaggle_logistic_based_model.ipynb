{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logit, Tree, RF, and LGBM\n",
    "1. Logistic Regression\n",
    "2. Decision Tree Classifier\n",
    "3. Random Forest Classifier\n",
    "4. Light Gradient Boosting Method\n",
    "\n",
    "# 1 Basic Procedures\n",
    "## 1.1 Importing necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sample_submission.csv', 'test.csv', 'train.csv']\n"
     ]
    }
   ],
   "source": [
    "# Based on kernel provided by Kaggle\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "\n",
    "import warnings\n",
    "import pprint\n",
    "\n",
    "# Data processing\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Style\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns # Seaborn visualization library\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "# File System\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Memory management\n",
    "import gc # Garbage Collector\n",
    "%matplotlib inline\n",
    "# %matplotlib inline is a kind of magic fucntion\n",
    "# it sets up the integration so you can create multiple plot windows without interfering with the console session;\n",
    "# no need to use plt.show() anymore;\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Read CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15.8 s\n",
      "Wall time: 17.3 s\n"
     ]
    }
   ],
   "source": [
    "# Read CSV\n",
    "%time train = pd.read_csv('../input/train.csv')\n",
    "%time test = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 How is the data like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_code  target    var_0   var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "0  train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187   \n",
       "1  train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208   \n",
       "2  train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427   \n",
       "\n",
       "     var_7   ...     var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  18.6266   ...      4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
       "1  16.5338   ...      7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
       "2  14.6155   ...      2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   7.8784   8.5635  12.7803  -1.0914  \n",
       "1   8.1267   8.7889  18.3560   1.9518  \n",
       "2  -6.5213   8.2675  14.7222   0.3965  \n",
       "\n",
       "[3 rows x 202 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at first 5 records of the train dataset\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (200000, 202) \n",
      "\n",
      "Test  shape: (200000, 201) \n",
      "\n",
      "Target variable:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    179902\n",
       "1     20098\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out the shape of the train and test sets\n",
    "print('Train shape:', train.shape,'\\n')\n",
    "print('Test  shape:', test.shape,'\\n')\n",
    "\n",
    "# Check the target values\n",
    "print('Target variable:')\n",
    "train['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import Imputer, MinMaxScaler\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score # , KFold\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Process data\n",
    "### Split X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable from the training set\n",
    "Target = train['target']\n",
    "\n",
    "# Input dataset for training and testing\n",
    "train_inp = train.drop(columns = ['target', 'ID_code'])\n",
    "test_inp  = test.drop(columns = ['ID_code'])\n",
    "\n",
    "# List of feature names\n",
    "features = list(train_inp.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Y_test:\n",
      "0    53951\n",
      "1     6049\n",
      "Name: target, dtype: int64 \n",
      "\n",
      "Shape of Train Set: (140000, 200)\n",
      "Shape of Test Set: (60000, 200)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training set and test set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(train_inp, Target, test_size= 0.3, random_state = 2019)\n",
    "print('Raw Y_test:')\n",
    "print(Y_test.value_counts(),'\\n')\n",
    "\n",
    "# check the shapes of training set and test set\n",
    "print('Shape of Train Set:', X_train.shape)\n",
    "print('Shape of Test Set:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare 5050 data (discarded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "# Make test set 50:50\n",
    "#Y_test5050 = pd.concat([Y_test[Y_test == 1], Y_test[Y_test == 0][:Y_test.sum()]])\n",
    "#X_test5050 = X_test.reindex(Y_test5050.index)\n",
    "#print('\\nProcessed Y_test:\\n', Y_test5050.value_counts())\n",
    "#print('\\nShape of X_test:\\n', X_test5050.shape)\n",
    "#print('\\nHead of X_test:\\n', X_test5050.head(3))\n",
    "#print('\\nHead of Y_test\\n', Y_test5050.head(3))\n",
    "\n",
    "# make training set 5050\n",
    "Y_train5050 = pd.concat([Y_train[Y_train == 1], Y_train[Y_train == 0][:Y_train.sum()]])\n",
    "X_train5050 = X_train.reindex(Y_train5050.index)\n",
    "#print('\\nProcessed Y_test:\\n', Y_train5050.value_counts())\n",
    "#print('\\nShape of X_train:\\n', X_train5050.shape)\n",
    "#print('\\nHead of X_test:\\n',X_train5050.head(3))\n",
    "#print('\\nHead of Y_test:\\n',Y_train5050.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 General Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance function\n",
    "def performance(Y_test, Y_pred):\n",
    "    \n",
    "    Y_pred_int = [0 if i < 0.5 else 1 for i in Y_pred]\n",
    "    \n",
    "    # Confusion matrix\n",
    "    print('\\nConfusion Matrix:')\n",
    "    print(confusion_matrix(Y_test, Y_pred_int)) \n",
    "    \n",
    "    # Classification report\n",
    "    print('\\nClassification Report:')\n",
    "    print(classification_report(Y_test, Y_pred_int))\n",
    "    \n",
    "    # AUC\n",
    "    fpr, tpr, thresholds = roc_curve(Y_test, Y_pred, pos_label=1)\n",
    "    print('AUC:')\n",
    "    print(auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Logistic Regression\n",
    "Logistic Regression is the most basic algorithm used for classification problems.\n",
    "* Future improvements:\n",
    "    * other solver (except lbfgs, liblinear), along with other penalty (l1)\n",
    "    * **Tuning the hyper-parameters**\n",
    "    * **ensemble learning methods**\n",
    "    * **cross validation** (Docu-sklearn P438: *sklearn.linear_model.LogisticRegressionCV*)\n",
    "* Problems:\n",
    "    * do I need to change the loss function?\n",
    "* Other things about logistic regression:\n",
    "    * If not specifying a solver, there will be \"FutureWarning: Default solver will be changed to 'lbfgs' in 0.22.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Logit in default\n",
    "* Reference: Sklearn-Documentation P1798 *sklearn.linear_model.LogisticRegression*\n",
    "    * in default in v0.20, penalty = 'l2', class_weight = 'balanced', solver = 'liblinear'\n",
    "* Unbalanced Model has AUC of 0.6. So we set class_weight = 'balanced'.\n",
    "* Solver:\n",
    "    * 'liblinear': slow but higher AUC.\n",
    "    * 'lbfgs':\n",
    "        * faster but **max_iter makes big difference, need more revision**;\n",
    "    * **need more reflection on solver**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 lbfgs 1000 (0.8566)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 4s\n",
      "\n",
      "Confusion Matrix:\n",
      "[[42271 11680]\n",
      " [ 1397  4652]]\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.78      0.87     53951\n",
      "          1       0.28      0.77      0.42      6049\n",
      "\n",
      "avg / total       0.90      0.78      0.82     60000\n",
      "\n",
      "AUC:\n",
      "0.8566043771973504\n"
     ]
    }
   ],
   "source": [
    "# Create an object of Logistic Regression with default parameters\n",
    "logist = LogisticRegression(penalty = 'l2', class_weight = 'balanced', solver = 'lbfgs', max_iter = 1000)\n",
    "# Fit the training data on this object\n",
    "%time logist.fit(X_train, Y_train)\n",
    "# Predict Y\n",
    "Y_pred = logist.predict_proba(X_test)[:,1] # array, no need to be series\n",
    "# print the score\n",
    "performance(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 liblinear (0.8582)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8min 30s\n",
      "\n",
      "Confusion Matrix:\n",
      "[[42381 11570]\n",
      " [ 1387  4662]]\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.79      0.87     53951\n",
      "          1       0.29      0.77      0.42      6049\n",
      "\n",
      "avg / total       0.90      0.78      0.82     60000\n",
      "\n",
      "AUC:\n",
      "0.8582670021911073\n"
     ]
    }
   ],
   "source": [
    "# Create an object of Logistic Regression with default parameters\n",
    "logist = LogisticRegression(penalty = 'l2', class_weight = 'balanced', solver = 'liblinear')\n",
    "# Fit the training data on this object\n",
    "%time logist.fit(X_train, Y_train)\n",
    "# Predict Y\n",
    "Y_pred = logist.predict_proba(X_test)[:,1] # array, no need to be series\n",
    "# print the score\n",
    "performance(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The precision of '1' is bad (only 0.28).\n",
    "* Penalty:\n",
    "    * smaller C = 0.001 (enhanced penalty) makes acc worse;\n",
    "    * bigger C makes no difference;\n",
    "    * so every feature counts;\n",
    "    * better no more feature selection on logit!\n",
    "    * that is, assuming no overfitting simply on 200 var.\n",
    "    * **need more reflection on penalty on logit**.\n",
    "* Try another method for unbalanced classification, training set 5050, in 2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 5050 Training\n",
    "* Not better than balanced method.\n",
    "* Suitable for further test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 lbfgs 1000 (0.8554)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 13.1 s\n",
      "\n",
      "Confusion Matrix:\n",
      "[[42079 11872]\n",
      " [ 1393  4656]]\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.78      0.86     53951\n",
      "          1       0.28      0.77      0.41      6049\n",
      "\n",
      "avg / total       0.90      0.78      0.82     60000\n",
      "\n",
      "AUC:\n",
      "0.8554300751569179\n"
     ]
    }
   ],
   "source": [
    "# Create an object of Logistic Regression with default parameters\n",
    "logist = LogisticRegression(penalty = 'l2', solver = 'lbfgs', max_iter = 1000)\n",
    "# Fit the training data on this object\n",
    "%time logist.fit(X_train5050, Y_train5050)\n",
    "# Predict Y\n",
    "Y_pred = logist.predict_proba(X_test)[:,1] # array, no need to be series\n",
    "# print the score\n",
    "performance(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 liblinear (0.8572) baseline!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 52.5 s\n",
      "\n",
      "Confusion Matrix:\n",
      "[[42188 11763]\n",
      " [ 1375  4674]]\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.78      0.87     53951\n",
      "          1       0.28      0.77      0.42      6049\n",
      "\n",
      "avg / total       0.90      0.78      0.82     60000\n",
      "\n",
      "AUC:\n",
      "0.8571943947754016\n"
     ]
    }
   ],
   "source": [
    "# Create an object of Logistic Regression with default parameters\n",
    "logist = LogisticRegression(penalty = 'l2', solver = 'liblinear')\n",
    "# Fit the training data on this object\n",
    "%time logist.fit(X_train5050, Y_train5050)\n",
    "# Predict Y\n",
    "Y_pred = logist.predict_proba(X_test)[:,1] # array, no need to be series\n",
    "# print the score\n",
    "performance(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 liblinear l1 (0.8572)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14min 52s\n",
      "\n",
      "Confusion Matrix:\n",
      "[[42206 11745]\n",
      " [ 1371  4678]]\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.78      0.87     53951\n",
      "          1       0.28      0.77      0.42      6049\n",
      "\n",
      "avg / total       0.90      0.78      0.82     60000\n",
      "\n",
      "AUC:\n",
      "0.8572671511080975\n"
     ]
    }
   ],
   "source": [
    "# Create an object of Logistic Regression with default parameters\n",
    "logist = LogisticRegression(penalty = 'l1', solver = 'liblinear')\n",
    "# Fit the training data on this object\n",
    "%time logist.fit(X_train5050, Y_train5050)\n",
    "# Predict Y\n",
    "Y_pred = logist.predict_proba(X_test)[:,1] # array, no need to be series\n",
    "# print the score\n",
    "performance(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Some Feature engineering (Corr and scaling)\n",
    "* Reflections:\n",
    "    1. scaling:\n",
    "        * StandardScaler: de_mean and di_std\n",
    "        * MinMaxScaler: de_mean and di_range\n",
    "    2. correlation? Nope.\n",
    "* Future Improvemtns on Feature Engineering:\n",
    "    1. histogram on 199 var -> continuous or discrete?\n",
    "    2. JB test on 199 var -> normal distribution?\n",
    "    3. generate new features.\n",
    "* **Need more reflection on feature engineering, according to 3.4.3 of Docu-sklearn**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Correlation: Neglectable\n",
    "* Hence:\n",
    "    * no PCA or similar de-dim methods;\n",
    "    * no overfitting on simply 200 var;\n",
    "    * no feature selection on simply 200 var."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biggest corr of X_train:  0.012902343440453178\n",
      "Wall time: 22.6 s\n"
     ]
    }
   ],
   "source": [
    "# find the biggest correlation_abs from \n",
    "%time print('Biggest corr of X_train: ', np.max(np.sort(np.abs(X_train.corr().values))[:,-2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Standardize (Scaling): Neglectable\n",
    "* Tried two methods:\n",
    "    * by StandardScaler\n",
    "    * by MinMaxScaler\n",
    "* **Need more experiments on feature scaling and other engineering**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "scaler1 = StandardScaler()\n",
    "scaler2 = MinMaxScaler()\n",
    "X_train5050_scaled1 = scaler1.fit_transform(X_train5050)\n",
    "X_train5050_scaled2 = scaler2.fit_transform(X_train5050)\n",
    "X_test_scaled1 = scaler1.fit_transform(X_test)\n",
    "X_test_scaled2 = scaler2.fit_transform(X_test)\n",
    "X_train_scaled1 = scaler1.fit_transform(X_train)\n",
    "X_train_scaled2 = scaler2.fit_transform(X_train)\n",
    "test_inp_scaled1 = scaler1.fit_transform(test_inp)\n",
    "test_inp_scaled2 = scaler2.fit_transform(test_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 509 ms\n",
      "\n",
      "Confusion Matrix:\n",
      "[[30144 23807]\n",
      " [  563  5486]]\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.56      0.71     53951\n",
      "          1       0.19      0.91      0.31      6049\n",
      "\n",
      "avg / total       0.90      0.59      0.67     60000\n",
      "\n",
      "AUC:\n",
      "0.8578249578299619\n",
      "Wall time: 831 ms\n",
      "\n",
      "Confusion Matrix:\n",
      "[[39139 14812]\n",
      " [ 1070  4979]]\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.73      0.83     53951\n",
      "          1       0.25      0.82      0.39      6049\n",
      "\n",
      "avg / total       0.90      0.74      0.79     60000\n",
      "\n",
      "AUC:\n",
      "0.8579402820102746\n"
     ]
    }
   ],
   "source": [
    "# scaler1 5050\n",
    "logist = LogisticRegression(penalty = 'l2', solver = 'liblinear')\n",
    "%time logist.fit(X_train5050_scaled1, Y_train5050)\n",
    "Y_pred = logist.predict_proba(X_test_scaled1)[:,1]\n",
    "performance(Y_test, Y_pred)\n",
    "# scaler2 5050\n",
    "logist = LogisticRegression(penalty = 'l2', solver = 'liblinear')\n",
    "%time logist.fit(X_train5050_scaled2, Y_train5050)\n",
    "Y_pred = logist.predict_proba(X_test_scaled2)[:,1]\n",
    "performance(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Baseline: balanced, liblinear, l2, minmaxscaler (0.8589) (0.860 submitted!)\n",
    "After experiments above, we come to the final model.\n",
    "* StandardScaler: 0.8588\n",
    "* MinMaxScaler: 0.8589"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.49 s\n",
      "\n",
      "Confusion Matrix:\n",
      "[[53202   749]\n",
      " [ 4400  1649]]\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.99      0.95     53951\n",
      "          1       0.69      0.27      0.39      6049\n",
      "\n",
      "avg / total       0.90      0.91      0.90     60000\n",
      "\n",
      "AUC:\n",
      "0.8588551567363806\n"
     ]
    }
   ],
   "source": [
    "# scaler1\n",
    "logist = LogisticRegression(penalty = 'l2', solver = 'liblinear')\n",
    "%time logist.fit(X_train_scaled1, Y_train)\n",
    "Y_pred = logist.predict_proba(X_test_scaled1)[:,1]\n",
    "performance(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.22 s\n",
      "\n",
      "Confusion Matrix:\n",
      "[[53327   624]\n",
      " [ 4550  1499]]\n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.99      0.95     53951\n",
      "          1       0.71      0.25      0.37      6049\n",
      "\n",
      "avg / total       0.90      0.91      0.89     60000\n",
      "\n",
      "AUC:\n",
      "0.8588915563521191\n"
     ]
    }
   ],
   "source": [
    "# scaler2 5050\n",
    "logist = LogisticRegression(penalty = 'l2', solver = 'liblinear')\n",
    "%time logist.fit(X_train_scaled2, Y_train)\n",
    "Y_pred = logist.predict_proba(X_test_scaled2)[:,1]\n",
    "performance(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eli\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ID_code    target\n",
      "0  test_0  0.177362\n",
      "1  test_1  0.242349\n",
      "2  test_2  0.040132\n",
      "3  test_3  0.207865\n",
      "4  test_4  0.060129\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1f17e25c4a8>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the Submission\n",
    "Y_pred = logist.predict_proba(test_inp_scaled2)[:,1]\n",
    "submit = test[['ID_code']]\n",
    "submit['target'] = Y_pred\n",
    "print(submit.head())\n",
    "submit.to_csv('log_reg_baseline.csv', index = False)\n",
    "submit['target'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 K-Folder Cross Validation\n",
    "* When I need to find hyperparameters, I need to use validation set, or alternatively use cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 48.8 s\n",
      "Accuracy CV:  0.7679781782112746\n"
     ]
    }
   ],
   "source": [
    "# 5050 CV on penalty parameters(grid search)\n",
    "logist = LogisticRegressionCV(solver = 'lbfgs', cv = 5)\n",
    "%time logist.fit(X_train5050, Y_train5050)\n",
    "print('Accuracy CV: ', logist.score(X_test5050, Y_test5050))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
